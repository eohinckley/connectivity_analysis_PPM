{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topography Analysis Pipelines\n",
    "These pipelines take already processed data and create subject/timepoint/condition-specific maps.\n",
    "\n",
    "### Data-prep pipeline\n",
    "* Downsample func data to 32k vertices\n",
    "* Compute distance matrix\n",
    "* Create vertex-wise correlation matrix\n",
    "\n",
    "### Network assignment pipeline\n",
    "* Apply distance cutoffs to create binary matrix\n",
    "* imput adjacency matrix and distance matrix to infomap algorithm\n",
    "* Repeat algorithm across 500 random seeds and average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.io import DataSink, SelectFiles, DataGrabber, FreeSurferSource # Data i/o\n",
    "from nipype.interfaces.utility import IdentityInterface, Function     # utility\n",
    "from nipype.pipeline.engine import Node, Workflow, MapNode, JoinNode        # pypeline engine\n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "#set output file type for FSL to NIFTI_GZ\n",
    "from nipype.interfaces.fsl.preprocess import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12/toolbox')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "# Set study variables\n",
    "study_home = '/data/perlman/moochie/user_data/CamachoCat/5YOP'\n",
    "preproc_dir = study_home + '/proc/preprocessing'\n",
    "hcpproc_dir = study_home + '/proc/hcp_proc'\n",
    "output_dir = study_home + '/proc/rest_mapping'\n",
    "workflow_dir = study_home + '/workflows'\n",
    "#session_info = read_csv(study_home + '/misc/session_info.csv',index_col=None)\n",
    "#session_info = session_info.astype({'subject_id':str})\n",
    "#subject_ids = session_info['subject_id'].unique().tolist()\n",
    "#subject_ids = list(map(str,subject_ids))\n",
    "subject_ids = ['5000']\n",
    "\n",
    "proc_cores = 6 # number of cores of processing for the workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab data\n",
    "\n",
    "# create connectivity matrices\n",
    "def cifti_conn_mat(cifti):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from subprocess import check_call\n",
    "    \n",
    "    conn_mat_cifti = cifti.replace('dtseries','dconn')\n",
    "    check_call(['wb_command -cifti-correlation', cifti, conn_mat_cifti])\n",
    "    \n",
    "    return(conn_mat_cifti)\n",
    "\n",
    "# create distance matrices\n",
    "def cifti_dist_mat(cifti):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from subprocess import check_call\n",
    "    import numpy as np\n",
    "    import nibabel as nib\n",
    "    from os.path import abspath\n",
    "    from os import rm\n",
    "    \n",
    "    img = nib.load(cifti)\n",
    "    d = cifti_img.get_fdata()\n",
    "    n_vertices = d.shape[0]\n",
    "    \n",
    "    d_mat = np.zeros((n_vertices,n_vertices))\n",
    "    \n",
    "    for vertex in range(0,n_vertices):\n",
    "        check_call(['wb_command -surface-geodesic-distance',cifti,str(vertex),'d_temp.shape.gii'])\n",
    "        temp = nib.load('d_temp.shape.gii')\n",
    "        d_mat[:,vertex]=temp.agg_data()\n",
    "    \n",
    "    np.save('dmat.npy',d_mat)\n",
    "    dist_mat_file=abspath('dmat.npy')\n",
    "    return(dist_mat_file)\n",
    "\n",
    "\n",
    "def combine_hemi_dist_mats(left_hemi_mat,right_hemi_mat,fillzeroes):\n",
    "    \n",
    "    return(full_dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gifti='/data/perlman/moochie/user_data/CamachoCat/5YOP/proc/hcp_proc/3000/T1w/fsaverage_LR32k/3000.R.midthickness.32k_fs_LR.surf.gii'\n",
    "\n",
    "from subprocess import check_call\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "img = nib.load(gifti)\n",
    "d = img.agg_data()\n",
    "n_vertices = d[0].shape[0]\n",
    "\n",
    "d_mat = np.zeros((n_vertices,n_vertices))\n",
    "\n",
    "for vertex in range(0,n_vertices):\n",
    "    check_call(['wb_command','-surface-geodesic-distance',gifti,str(vertex),'d_temp.shape.gii'])\n",
    "    temp = nib.load('d_temp.shape.gii')\n",
    "    d_mat[:,vertex]=temp.agg_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mat[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Rhemi.txt',d_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import hcp_utils as hcp\n",
    "import numpy as np\n",
    "\n",
    "cifti1 = '/data/perlman/moochie/user_data/CamachoCat/5YOP/proc/hcp_proc/3000/MNINonLinear/fsaverage_LR32k/3000.thickness.32k_fs_LR.dscalar.nii'\n",
    "cifti2 = '/data/perlman/moochie/user_data/CamachoCat/5YOP/5yop/distance1R.shape.gii'\n",
    "cifti3 = ''\n",
    "cifti_img = nib.load(cifti2)\n",
    "#data = cifti_img.get_fdata()\n",
    "d = cifti_img.agg_data()\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_conn_mat = Node(Function(input_names=['cifti'],output_names=['conn_mat_cifti'],\n",
    "                              function=cifti_conn_mat),name='make_conn_mat')\n",
    "\n",
    "make_Ldist_mat = Node(Function(input_names=['cifti'],output_names=['dist_mat_file'],\n",
    "                               name='make_dist_mat'),name='make_Ldist_mat')\n",
    "\n",
    "make_Rdist_mat = Node(Function(input_names=['cifti'],output_names=['dist_mat_file'],\n",
    "                               name='make_dist_mat'),name='make_Rdist_mat')\n",
    "\n",
    "combine_dist_mats = Node(Function(input_names=['left_hemi_mat','right_hemi_mat','fillzeroes'], \n",
    "                                  output_names=['full_dist_mat'],\n",
    "                                  function=combine_hemi_dist_mats),name='combine_dist_mats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import hcp_utils as hcp\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "func_data_file = input_dir +'/{0}/MNINonLinear/Results/movie/movie_Atlas.dconn.nii'.format(subject_id)\n",
    "func_img = nib.load(func_data_file)\n",
    "hemi2_func_data = func_img.get_fdata()\n",
    "hemi1_func_data = hemi2_func_data[:29696,:29696]\n",
    "hemi2_func_data = hemi2_func_data[29696:59412,29696:59412]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [str(a) for a in range(0,hemi1_func_data.shape[0])]\n",
    "\n",
    "nodes_weights = open('movie_h1_nodes_nothresh_weights.txt','a')\n",
    "y=0\n",
    "while y < hemi1_func_data.shape[0]:\n",
    "    for x in range(y,hemi1_func_data.shape[0]-1):\n",
    "        #z = 0.5*(np.log10(1+hemi1_func_data[x,x+1]) - np.log10(1-hemi1_func_data[x,x+1]))\n",
    "        #if z>0.05:\n",
    "        nodes_weights.write('{0} {1} {2}\\n'.format(labels[x],labels[x+1],hemi1_func_data[x,x+1]))\n",
    "    y = y+1\n",
    "    \n",
    "    \n",
    "nodes_weights = open('movie_h2_nodes_nothresh_weights.txt','a')\n",
    "labels = [str(a + 29696) for a in range(0,hemi2_func_data.shape[0])]   \n",
    "y=0\n",
    "while y < hemi2_func_data.shape[0]:\n",
    "    for x in range(y,hemi2_func_data.shape[0]-1):\n",
    "        #z = 0.5*(np.log10(1+hemi2_func_data[x,x+1]) - np.log10(1-hemi2_func_data[x,x+1]))\n",
    "        #if z>0.05:\n",
    "        nodes_weights.write('{0} {1} {2}\\n'.format(labels[x],labels[x+1],hemi2_func_data[x,x+1]))\n",
    "    y = y+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "orig_img = nib.load('/data/perlman/moochie/user_data/CamachoCat/5YOP/hcp_proc/3000/MNINonLinear/Results/firstvol/firstvol_Atlas.dtseries.nii')\n",
    "orig_data = orig_img.get_fdata()\n",
    "print(orig_data.shape)\n",
    "new_data = np.zeros(orig_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from igraph import Graph\n",
    "import random\n",
    "random.seed(540000)\n",
    "gnodes = Graph.Read_Ncol('fixation_h1_nodes_nothresh_weights.txt', names=('node1','node2','weight'), weights=True)\n",
    "mods1 = gnodes.community_infomap(edge_weights='weight',trials=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "net1_labels = np.array(mods1.membership) + 1\n",
    "n,c=np.unique(net1_labels,return_counts=True)\n",
    "print(n)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(n)):\n",
    "    if c[i]<100:\n",
    "        net1_labels[net1_labels==n[i]]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net1_labels.shape)\n",
    "new_data[0,0:29696] = net1_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = nib.cifti2.cifti2.Cifti2Image(new_data, header = orig_img.header, nifti_header=orig_img.nifti_header)\n",
    "nib.save(new_img, 'fixation_left_hemi.dtseries.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnodes2 = Graph.Read_Ncol('fixation_h2_nodes_nothresh_weights.txt', names=('node1','node2','weight'), weights=True, directed=True)\n",
    "mods2 = gnodes2.community_infomap(edge_weights='weight',trials=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2_labels = np.array(mods2.membership) + 1\n",
    "n,c=np.unique(net2_labels,return_counts=True)\n",
    "print(n)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(n)):\n",
    "    if c[i]<100:\n",
    "        net2_labels[net2_labels==n[i]]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net2_labels.shape)\n",
    "new_data[0,29696:59412] = net2_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = nib.cifti2.cifti2.Cifti2Image(new_data, header = orig_img.header, nifti_header=orig_img.nifti_header)\n",
    "nib.save(new_img, 'fixation_right_hemi.dtseries.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.io import DataSink, SelectFiles, DataGrabber, FreeSurferSource # Data i/o\n",
    "from nipype.interfaces.utility import IdentityInterface, Function     # utility\n",
    "from nipype.pipeline.engine import Node, Workflow, MapNode, JoinNode        # pypeline engine\n",
    "from pandas import DataFrame, read_csv\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#set output file type for FSL to NIFTI_GZ\n",
    "from nipype.interfaces.fsl.preprocess import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12/toolbox')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "# Set study variables\n",
    "study_home = '/Users/SEAlab/Documents/PPM'\n",
    "hcpproc_dir = study_home + '/Data'\n",
    "workflow_dir = study_home + '/Workflows'\n",
    "cov_file = study_home + '/Misc/covariates.csv'\n",
    "cov_dataframe = read_csv(cov_file,index_col=None)\n",
    "cov_dataframe = cov_dataframe.sort_values(by='folder')\n",
    "\n",
    "analysis='postpartum' #Enter preg or postpartum depending on analysis being run\n",
    "if analysis=='preg':\n",
    "    output_dir = study_home + '/fMRIproc/longitudinal_preg'\n",
    "    cov_dataframe = cov_dataframe[cov_dataframe['age']<40]\n",
    "elif analysis=='postpartum':\n",
    "    output_dir = study_home + '/fMRIproc/longitudinal_pp'\n",
    "    cov_dataframe = cov_dataframe[cov_dataframe['age']>40]\n",
    "\n",
    "# set analysis specs\n",
    "n_slices = 4\n",
    "data_type = 'cortical_thickness'\n",
    "\n",
    "# set model specifications\n",
    "model = smf.ols\n",
    "model_formula = 'Y ~ age'\n",
    "n_terms = 1\n",
    "\n",
    "proc_cores = 2 # number of cores of processing for the workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data handling nodes\n",
    "\n",
    "# grab data\n",
    "def pull_data(data_dict,data_label):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from glob import glob\n",
    "    \n",
    "    file_list = sorted(glob(data_dict[data_label]))\n",
    "    \n",
    "    return(file_list)\n",
    "\n",
    "selectfiles = Node(Function(input_names=['data_dict','data_label'],\n",
    "                            output_names=['file_list'],\n",
    "                            function=pull_data), name='selectfiles')\n",
    "selectfiles.inputs.data_label = data_type\n",
    "\n",
    "if analysis=='preg':\n",
    "    selectfiles.inputs.data_dict={'cortical_thickness':hcpproc_dir + '/*_Preg*/MNINonLinear/fsaverage_LR32k/*.thickness.32k_fs_LR.dscalar.nii',\n",
    "                             'functional_connectivity':hcpproc_dir + ''}\n",
    "elif analysis=='postpartum':\n",
    "    selectfiles.inputs.data_dict={'cortical_thickness':hcpproc_dir + '/*_PP*/MNINonLinear/fsaverage_LR32k/*.thickness.32k_fs_LR.dscalar.nii',\n",
    "                             'functional_connectivity':hcpproc_dir + ''}\n",
    "\n",
    "# sink data\n",
    "substitutions = []\n",
    "datasink = Node(DataSink(),name='datasink')\n",
    "datasink.inputs.base_directory = output_dir\n",
    "datasink.inputs.container = output_dir\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index for cifti file\n",
    "def create_indexing(file_list,n_slices):\n",
    "    import nibabel as nib\n",
    "    import numpy as np\n",
    "    from sklearn.utils import Bunch\n",
    "\n",
    "    img1 = nib.load(file_list[0])\n",
    "    Y1 = img1.get_fdata()\n",
    "    N = Y1.shape[0]\n",
    "    M = Y1.shape[1]\n",
    "    indexes=Bunch()\n",
    "\n",
    "    index_labels = ['slice{0}'.format(a) for a in range(0,n_slices)]\n",
    "    width = int(M/n_slices)\n",
    "    start=0\n",
    "    end=width\n",
    "    i=0\n",
    "    while end<M:\n",
    "        indexes[index_labels[i]]=slice(start,end)\n",
    "        start+=width\n",
    "        end+=width\n",
    "        i+=1\n",
    "    if end-width<M:\n",
    "        indexes[index_labels[i]]=slice(start,M)\n",
    "    indexes_list = [indexes[x] for x in indexes.keys()]\n",
    "    return(indexes_list)\n",
    "\n",
    "# pull data from the same slice for each file\n",
    "def agg_data(file_list,index):\n",
    "    import nibabel as nib\n",
    "    import numpy as np\n",
    "    from os.path import basename, abspath\n",
    "    \n",
    "    data_stack = []\n",
    "    for file in file_list:\n",
    "        img = nib.load(file)\n",
    "        temp = img.get_fdata()\n",
    "        temp = temp[:,index]\n",
    "        temp_file = basename(file).replace('.nii','.slice.npy')\n",
    "        np.save(temp_file,temp)\n",
    "        data_stack.append(abspath(temp_file))\n",
    "        \n",
    "    return(data_stack)\n",
    "\n",
    "# run models on data\n",
    "def run_long_models(model,model_formula,data_stack,covariates,n_terms):\n",
    "    import numpy as np\n",
    "    from os.path import basename,abspath\n",
    "\n",
    "    data_list = []\n",
    "    for d in data_stack:\n",
    "        t = np.load(d)\n",
    "        t = np.expand_dims(t,axis=2)\n",
    "        data_list.append(t)\n",
    "\n",
    "    sub_data = np.concatenate(data_list, axis=2)\n",
    "\n",
    "    m = sub_data.shape[0]\n",
    "    n = sub_data.shape[1]\n",
    "\n",
    "    p_vals = np.zeros((m,n,n_terms+1))\n",
    "    t_vals = np.zeros((m,n,n_terms+1))\n",
    "    beta_vals = np.zeros((m,n,n_terms+1))\n",
    "\n",
    "    for a in range(0,m):\n",
    "        for b in range(0,n):\n",
    "            covariates['Y'] = sub_data[a,b,:]\n",
    "            mdl = model(formula=model_formula, data=covariates).fit()\n",
    "            beta_vals[a,b,:] = mdl.params\n",
    "            p_vals[a,b,:] = mdl.pvalues\n",
    "            t_vals[a,b,:] = mdl.tvalues\n",
    "\n",
    "    p_file = 'p_slice.npy'\n",
    "    t_file = 't_slice.npy'\n",
    "    beta_file = 'beta_slice.npy'\n",
    "\n",
    "    np.save(p_file,p_vals)\n",
    "    np.save(t_file, t_vals)\n",
    "    np.save(beta_file,beta_vals)\n",
    "\n",
    "    p_slice = abspath(p_file)\n",
    "    t_slice = abspath(t_file)\n",
    "    beta_slice = abspath(beta_file)\n",
    "    return(p_slice,beta_slice,t_slice)\n",
    "\n",
    "# reconstitute the results into cifti files\n",
    "def combine_data(p_list,beta_list,t_list,index_list,n_terms,file_list):\n",
    "    import nibabel as nib\n",
    "    import numpy as np\n",
    "    from os.path import abspath\n",
    "    \n",
    "    img = nib.load(file_list[0])\n",
    "    img_data = img.get_fdata()\n",
    "\n",
    "    p_data = np.empty((img_data.shape[0],img_data.shape[1],n_terms+1))\n",
    "    t_data = np.empty((img_data.shape[0],img_data.shape[1],n_terms+1))\n",
    "    beta_data = np.empty((img_data.shape[0],img_data.shape[1],n_terms+1))\n",
    "    \n",
    "    print(index_list)\n",
    "\n",
    "    for x in range(0,len(index_list)):\n",
    "        p_data[:,index_list[x],:] = np.load(p_list[x])\n",
    "        t_data[:,index_list[x],:] = np.load(t_list[x])\n",
    "        beta_data[:,index_list[x],:] = np.load(beta_list[x])\n",
    "\n",
    "    # get cifti header info from first file\n",
    "    bm = img.header.get_axis(1)\n",
    "    sc = img.header.get_axis(0)\n",
    "    \n",
    "    pval_cifti = []\n",
    "    tstat_cifti = []\n",
    "    beta_cifti = []\n",
    "    \n",
    "    for x in range(0,n_terms+1):\n",
    "        # p-values\n",
    "        temp_p = p_data[:,:,x]\n",
    "        temp_p[temp_p>.05] = 1\n",
    "        sc.name = ['pvalues']\n",
    "        p_img = nib.cifti2.cifti2.Cifti2Image(temp_p,(sc,bm))\n",
    "        nib.save(p_img,'model_pvalues_term{0}.dscalar.nii'.format(x))\n",
    "        pval_cifti.append(abspath('model_pvalues_term{0}.dscalar.nii'.format(x)))\n",
    "        # t-values\n",
    "        temp_t = t_data[:,:,x]\n",
    "        temp_t[temp_p>.05] = 0\n",
    "        sc.name = ['tvalues']\n",
    "        t_img = nib.cifti2.cifti2.Cifti2Image(temp_t,(sc,bm))\n",
    "        nib.save(t_img,'model_tvalues_term{0}.dscalar.nii'.format(x))\n",
    "        tstat_cifti.append(abspath('model_tvalues_term{0}.dscalar.nii'.format(x)))\n",
    "        #beta values\n",
    "        temp_b = beta_data[:,:,x]\n",
    "        temp_b[temp_p>.05] = 0\n",
    "        sc.name = ['beta']\n",
    "        b_img = nib.cifti2.cifti2.Cifti2Image(temp_b,(sc,bm))\n",
    "        nib.save(b_img,'model_beta_term{0}.dscalar.nii'.format(x))\n",
    "        beta_cifti.append(abspath('model_beta_term{0}.dscalar.nii'.format(x)))\n",
    "    \n",
    "    return(pval_cifti,beta_cifti,tstat_cifti)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node to wrap the function that makes the list of indexes\n",
    "make_indexes = Node(Function(input_names=['file_list','n_slices'], output_names=['indexes_list'], \n",
    "                             function=create_indexing),name='create_indexing')\n",
    "make_indexes.inputs.n_slices=n_slices\n",
    "\n",
    "# Node to wrap the function that pulls the data to model\n",
    "pull_data = MapNode(Function(input_names=['file_list','index'],output_names=['data_stack'],\n",
    "                             function=agg_data),name='pull_data', iterfield=['index'])\n",
    "\n",
    "# Node to wrap the function that runs the longitudinal model\n",
    "run_models = MapNode(Function(input_names=['model','model_formula','data_stack','covariates','n_terms'],\n",
    "                              output_names=['p_slice','beta_slice','t_slice'], function=run_long_models),\n",
    "                     name='run_models',iterfield=['data_stack'])\n",
    "run_models.inputs.model=model\n",
    "run_models.inputs.model_formula=model_formula\n",
    "run_models.inputs.covariates=cov_dataframe\n",
    "run_models.inputs.n_terms=n_terms\n",
    "\n",
    "# Node to recombine the data slices for visualization\n",
    "recombine_data = Node(Function(input_names=['p_list','beta_list','t_list','index_list','n_terms','file_list'],\n",
    "                               output_names=['pval_cifti','beta_cifti','tstat_cifti'],function=combine_data),\n",
    "                      name='recombine_data')\n",
    "recombine_data.inputs.n_terms = n_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210701-16:07:08,929 nipype.workflow INFO:\n",
      "\t Workflow long_model settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "210701-16:07:08,945 nipype.workflow INFO:\n",
      "\t Running in parallel.\n",
      "210701-16:07:08,950 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "210701-16:07:09,47 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"long_model.selectfiles\".\n",
      "210701-16:07:09,52 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"long_model.selectfiles\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/selectfiles\".\n",
      "210701-16:07:09,66 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"long_model.selectfiles\".\n",
      "210701-16:07:09,102 nipype.workflow INFO:\n",
      "\t [Node] Running \"selectfiles\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "210701-16:07:09,291 nipype.workflow DEBUG:\n",
      "\t Needed files: /Users/SEAlab/Documents/PPM/Data/1196_PP1/MNINonLinear/fsaverage_LR32k/1196_PP1.thickness.32k_fs_LR.dscalar.nii;/Users/SEAlab/Documents/PPM/Data/1196_PP1/MNINonLinear/fsaverage_LR32k/1196_PP1.thickness.32k_fs_LR.dscalar.mat;/Users/SEAlab/Documents/PPM/Data/1196_PP2/MNINonLinear/fsaverage_LR32k/1196_PP2.thickness.32k_fs_LR.dscalar.nii;/Users/SEAlab/Documents/PPM/Data/1196_PP2/MNINonLinear/fsaverage_LR32k/1196_PP2.thickness.32k_fs_LR.dscalar.mat;/Users/SEAlab/Documents/PPM/Data/1196_PP3/MNINonLinear/fsaverage_LR32k/1196_PP3.thickness.32k_fs_LR.dscalar.nii;/Users/SEAlab/Documents/PPM/Data/1196_PP3/MNINonLinear/fsaverage_LR32k/1196_PP3.thickness.32k_fs_LR.dscalar.mat;/Users/SEAlab/Documents/PPM/Data/1196_PP4/MNINonLinear/fsaverage_LR32k/1196_PP4.thickness.32k_fs_LR.dscalar.nii;/Users/SEAlab/Documents/PPM/Data/1196_PP4/MNINonLinear/fsaverage_LR32k/1196_PP4.thickness.32k_fs_LR.dscalar.mat;/Users/SEAlab/Documents/PPM/Workflows/long_model/selectfiles/_0x598b717417dc7955d87b133ee6f879d1_unfinished.json;/Users/SEAlab/Documents/PPM/Workflows/long_model/selectfiles/_inputs.pklz;/Users/SEAlab/Documents/PPM/Workflows/long_model/selectfiles/_node.pklz\n",
      "210701-16:07:09,296 nipype.workflow DEBUG:\n",
      "\t Needed dirs: /Users/SEAlab/Documents/PPM/Workflows/long_model/selectfiles/_report\n",
      "210701-16:07:09,302 nipype.workflow DEBUG:\n",
      "\t Removing files: \n",
      "210701-16:07:09,310 nipype.workflow DEBUG:\n",
      "\t Saving results file: '/Users/SEAlab/Documents/PPM/Workflows/long_model/selectfiles/result_selectfiles.pklz'\n",
      "210701-16:07:09,320 nipype.workflow DEBUG:\n",
      "\t [Node] Writing post-exec report to \"/Users/SEAlab/Documents/PPM/Workflows/long_model/selectfiles/_report/report.rst\"\n",
      "210701-16:07:09,336 nipype.workflow INFO:\n",
      "\t [Node] Finished \"long_model.selectfiles\".\n",
      "210701-16:07:10,952 nipype.workflow INFO:\n",
      "\t [Job 0] Completed (long_model.selectfiles).\n",
      "210701-16:07:10,956 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "210701-16:07:11,20 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"long_model.create_indexing\".\n",
      "210701-16:07:11,24 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"long_model.create_indexing\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/create_indexing\".\n",
      "210701-16:07:11,38 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"long_model.create_indexing\".\n",
      "210701-16:07:11,73 nipype.workflow INFO:\n",
      "\t [Node] Running \"create_indexing\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "210701-16:07:11,578 nipype.workflow INFO:\n",
      "\t [Node] Finished \"long_model.create_indexing\".\n",
      "210701-16:07:12,953 nipype.workflow INFO:\n",
      "\t [Job 1] Completed (long_model.create_indexing).\n",
      "210701-16:07:12,956 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "210701-16:07:14,955 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 4 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "210701-16:07:15,6 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_pull_data0\".\n",
      "210701-16:07:15,9 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_pull_data0\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0\".\n",
      "210701-16:07:15,20 nipype.workflow DEBUG:\n",
      "\t [Node] Hashes: [('file_list', [('/Users/SEAlab/Documents/PPM/Data/1196_PP1/MNINonLinear/fsaverage_LR32k/1196_PP1.thickness.32k_fs_LR.dscalar.nii', '5513fee4425ac7b6f188d858bae92f20'), ('/Users/SEAlab/Documents/PPM/Data/1196_PP2/MNINonLinear/fsaverage_LR32k/1196_PP2.thickness.32k_fs_LR.dscalar.nii', '5e2078d3ae95261f87ad219bee55a174'), ('/Users/SEAlab/Documents/PPM/Data/1196_PP3/MNINonLinear/fsaverage_LR32k/1196_PP3.thickness.32k_fs_LR.dscalar.nii', '54ce678d535576a68da3a11d2e769a6d'), ('/Users/SEAlab/Documents/PPM/Data/1196_PP4/MNINonLinear/fsaverage_LR32k/1196_PP4.thickness.32k_fs_LR.dscalar.nii', '780477b1c14c4ca08d06464af7ee2f0b')]), ('function_str', \"def agg_data(file_list,index):\\n    import nibabel as nib\\n    import numpy as np\\n    from os.path import basename, abspath\\n\\n    data_stack = []\\n    for file in file_list:\\n        img = nib.load(file)\\n        temp = img.get_fdata()\\n        temp = temp[:,index]\\n        temp_file = basename(file).replace('.nii','.slice.npy')\\n        np.save(temp_file,temp)\\n        data_stack.append(abspath(temp_file))\\n\\n    return(data_stack)\\n\"), ('index', slice(0, 14853, None)), ('needed_outputs', ['data_stack'])], 5cb9415b1d83959d7ff0dcfaabd3d9f2, /Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/_0x5cb9415b1d83959d7ff0dcfaabd3d9f2.json, ['/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/_0x36ca47f32fccc7511f3a3bbe5ef63f3a.json']\n",
      "210701-16:07:15,27 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_pull_data0\".210701-16:07:15,30 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_pull_data1\".\n",
      "\n",
      "210701-16:07:15,34 nipype.workflow DEBUG:\n",
      "\t [Node] Old/new hashes = 36ca47f32fccc7511f3a3bbe5ef63f3a/5cb9415b1d83959d7ff0dcfaabd3d9f2210701-16:07:15,38 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_pull_data1\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data1\".\n",
      "\n",
      "210701-16:07:15,47 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_pull_data1\".\n",
      "210701-16:07:15,77 nipype.utils DEBUG:\n",
      "\t Removing contents of /Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0\n",
      "210701-16:07:15,167 nipype.workflow DEBUG:\n",
      "\t Unable to write a particular type to the json file\n",
      "210701-16:07:15,172 nipype.workflow INFO:\n",
      "\t [Node] Running \"_pull_data1\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "210701-16:07:15,174 nipype.workflow DEBUG:\n",
      "\t [Node] Writing pre-exec report to \"/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/_report/report.rst\"\n",
      "210701-16:07:15,180 nipype.workflow INFO:\n",
      "\t [Node] Running \"_pull_data0\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "210701-16:07:16,486 nipype.workflow DEBUG:\n",
      "\t Needed files: /Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/1196_PP1.thickness.32k_fs_LR.dscalar.slice.npy;/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/1196_PP2.thickness.32k_fs_LR.dscalar.slice.npy;/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/1196_PP3.thickness.32k_fs_LR.dscalar.slice.npy;/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/1196_PP4.thickness.32k_fs_LR.dscalar.slice.npy;/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/_0x5cb9415b1d83959d7ff0dcfaabd3d9f2_unfinished.json;/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/_inputs.pklz;/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/_node.pklz\n",
      "210701-16:07:16,489 nipype.workflow DEBUG:\n",
      "\t Needed dirs: /Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/_report\n",
      "210701-16:07:16,493 nipype.workflow DEBUG:\n",
      "\t Removing files: \n",
      "210701-16:07:16,497 nipype.workflow DEBUG:\n",
      "\t Saving results file: '/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/result__pull_data0.pklz'\n",
      "210701-16:07:16,510 nipype.workflow DEBUG:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Node] Writing post-exec report to \"/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/_report/report.rst\"\n",
      "210701-16:07:16,529 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_pull_data1\".\n",
      "210701-16:07:16,547 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_pull_data0\".\n",
      "210701-16:07:16,959 nipype.workflow INFO:\n",
      "\t [Job 6] Completed (_pull_data0).\n",
      "210701-16:07:16,961 nipype.workflow INFO:\n",
      "\t [Job 7] Completed (_pull_data1).\n",
      "210701-16:07:16,964 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 2 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "210701-16:07:17,18 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_pull_data2\".\n",
      "210701-16:07:17,22 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_pull_data2\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data2\".\n",
      "210701-16:07:17,29 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_pull_data3\".\n",
      "210701-16:07:17,28 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_pull_data2\".\n",
      "210701-16:07:17,32 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_pull_data3\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3\".\n",
      "210701-16:07:17,45 nipype.workflow DEBUG:\n",
      "\t [Node] Hashes: [('file_list', [('/Users/SEAlab/Documents/PPM/Data/1196_PP1/MNINonLinear/fsaverage_LR32k/1196_PP1.thickness.32k_fs_LR.dscalar.nii', '5513fee4425ac7b6f188d858bae92f20'), ('/Users/SEAlab/Documents/PPM/Data/1196_PP2/MNINonLinear/fsaverage_LR32k/1196_PP2.thickness.32k_fs_LR.dscalar.nii', '5e2078d3ae95261f87ad219bee55a174'), ('/Users/SEAlab/Documents/PPM/Data/1196_PP3/MNINonLinear/fsaverage_LR32k/1196_PP3.thickness.32k_fs_LR.dscalar.nii', '54ce678d535576a68da3a11d2e769a6d'), ('/Users/SEAlab/Documents/PPM/Data/1196_PP4/MNINonLinear/fsaverage_LR32k/1196_PP4.thickness.32k_fs_LR.dscalar.nii', '780477b1c14c4ca08d06464af7ee2f0b')]), ('function_str', \"def agg_data(file_list,index):\\n    import nibabel as nib\\n    import numpy as np\\n    from os.path import basename, abspath\\n\\n    data_stack = []\\n    for file in file_list:\\n        img = nib.load(file)\\n        temp = img.get_fdata()\\n        temp = temp[:,index]\\n        temp_file = basename(file).replace('.nii','.slice.npy')\\n        np.save(temp_file,temp)\\n        data_stack.append(abspath(temp_file))\\n\\n    return(data_stack)\\n\"), ('index', slice(44559, 59412, None)), ('needed_outputs', ['data_stack'])], 12a20ca74fcf75c95ac7bfc59a0f51b1, /Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/_0x12a20ca74fcf75c95ac7bfc59a0f51b1.json, ['/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/_0xa29c92015602d61fe51ac96bbe307dfd.json']\n",
      "210701-16:07:17,49 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_pull_data3\".\n",
      "210701-16:07:17,54 nipype.workflow DEBUG:\n",
      "\t [Node] Old/new hashes = a29c92015602d61fe51ac96bbe307dfd/12a20ca74fcf75c95ac7bfc59a0f51b1\n",
      "210701-16:07:17,78 nipype.utils DEBUG:\n",
      "\t Removing contents of /Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3\n",
      "210701-16:07:17,93 nipype.workflow INFO:\n",
      "\t [Node] Running \"_pull_data2\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "210701-16:07:17,127 nipype.workflow DEBUG:\n",
      "\t Unable to write a particular type to the json file\n",
      "210701-16:07:17,131 nipype.workflow DEBUG:\n",
      "\t [Node] Writing pre-exec report to \"/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/_report/report.rst\"\n",
      "210701-16:07:17,141 nipype.workflow INFO:\n",
      "\t [Node] Running \"_pull_data3\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "210701-16:07:18,251 nipype.workflow DEBUG:\n",
      "\t Needed files: /Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/1196_PP1.thickness.32k_fs_LR.dscalar.slice.npy;/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/1196_PP2.thickness.32k_fs_LR.dscalar.slice.npy;/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/1196_PP3.thickness.32k_fs_LR.dscalar.slice.npy;/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/1196_PP4.thickness.32k_fs_LR.dscalar.slice.npy;/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/_0x12a20ca74fcf75c95ac7bfc59a0f51b1_unfinished.json;/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/_inputs.pklz;/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/_node.pklz\n",
      "210701-16:07:18,255 nipype.workflow DEBUG:\n",
      "\t Needed dirs: /Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/_report\n",
      "210701-16:07:18,266 nipype.workflow DEBUG:\n",
      "\t Removing files: \n",
      "210701-16:07:18,272 nipype.workflow DEBUG:\n",
      "\t Saving results file: '/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/result__pull_data3.pklz'\n",
      "210701-16:07:18,280 nipype.workflow DEBUG:\n",
      "\t [Node] Writing post-exec report to \"/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/_report/report.rst\"\n",
      "210701-16:07:18,286 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_pull_data2\".\n",
      "210701-16:07:18,295 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_pull_data3\".\n",
      "210701-16:07:18,962 nipype.workflow INFO:\n",
      "\t [Job 8] Completed (_pull_data2).\n",
      "210701-16:07:18,963 nipype.workflow INFO:\n",
      "\t [Job 9] Completed (_pull_data3).\n",
      "210701-16:07:18,965 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "210701-16:07:19,23 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"long_model.pull_data\".\n",
      "210701-16:07:19,26 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"long_model.pull_data\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data\".\n",
      "210701-16:07:19,32 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"long_model.pull_data\".\n",
      "210701-16:07:19,53 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_pull_data0\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0\".\n",
      "210701-16:07:19,63 nipype.workflow INFO:\n",
      "\t [Node] Cached \"_pull_data0\" - collecting precomputed outputs\n",
      "210701-16:07:19,67 nipype.workflow INFO:\n",
      "\t [Node] \"_pull_data0\" found cached.\n",
      "210701-16:07:19,82 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_pull_data1\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data1\".\n",
      "210701-16:07:19,90 nipype.workflow INFO:\n",
      "\t [Node] Cached \"_pull_data1\" - collecting precomputed outputs\n",
      "210701-16:07:19,95 nipype.workflow INFO:\n",
      "\t [Node] \"_pull_data1\" found cached.\n",
      "210701-16:07:19,102 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_pull_data2\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data2\".\n",
      "210701-16:07:19,113 nipype.workflow INFO:\n",
      "\t [Node] Cached \"_pull_data2\" - collecting precomputed outputs\n",
      "210701-16:07:19,117 nipype.workflow INFO:\n",
      "\t [Node] \"_pull_data2\" found cached.\n",
      "210701-16:07:19,128 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_pull_data3\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3\".\n",
      "210701-16:07:19,135 nipype.workflow INFO:\n",
      "\t [Node] Cached \"_pull_data3\" - collecting precomputed outputs\n",
      "210701-16:07:19,144 nipype.workflow INFO:\n",
      "\t [Node] \"_pull_data3\" found cached.\n",
      "210701-16:07:19,157 nipype.workflow INFO:\n",
      "\t [Node] Finished \"long_model.pull_data\".\n",
      "210701-16:07:20,965 nipype.workflow INFO:\n",
      "\t [Job 2] Completed (long_model.pull_data).\n",
      "210701-16:07:20,968 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "210701-16:07:22,968 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 4 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "210701-16:07:23,19 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_run_models0\".\n",
      "210701-16:07:23,24 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_run_models0\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0\".210701-16:07:23,28 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_run_models1\".\n",
      "\n",
      "210701-16:07:23,42 nipype.workflow DEBUG:\n",
      "\t [Node] Hashes: [('covariates',      folder  age\n",
      "5  1196_PP1   68\n",
      "6  1196_PP2   76\n",
      "7  1196_PP3   96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  1196_PP4  106), ('data_stack', [('/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/1196_PP1.thickness.32k_fs_LR.dscalar.slice.npy', '6bf481f7c42e4cc9b57d14f1da33c99f'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/1196_PP2.thickness.32k_fs_LR.dscalar.slice.npy', '99e4af043a53c61c57b81ee8b1d88e61'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/1196_PP3.thickness.32k_fs_LR.dscalar.slice.npy', '5da344927d4d83959d198349ed5d7171'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data0/1196_PP4.thickness.32k_fs_LR.dscalar.slice.npy', 'e6fc8850eeda4d6b433c637aa50a030c')]), ('function_str', \"def run_long_models(model,model_formula,data_stack,covariates,n_terms):\\n    import numpy as np\\n    from os.path import basename,abspath\\n\\n    data_list = []\\n    for d in data_stack:\\n        t = np.load(d)\\n        t = np.expand_dims(t,axis=2)\\n        data_list.append(t)\\n\\n    sub_data = np.concatenate(data_list, axis=2)\\n\\n    m = sub_data.shape[0]\\n    n = sub_data.shape[1]\\n\\n    p_vals = np.zeros((m,n,n_terms+1))\\n    t_vals = np.zeros((m,n,n_terms+1))\\n    beta_vals = np.zeros((m,n,n_terms+1))\\n\\n    for a in range(0,m):\\n        for b in range(0,n):\\n            covariates['Y'] = sub_data[a,b,:]\\n            mdl = model(formula=model_formula, data=covariates).fit()\\n            beta_vals[a,b,:] = mdl.params\\n            p_vals[a,b,:] = mdl.pvalues\\n            t_vals[a,b,:] = mdl.tvalues\\n\\n    p_file = 'p_slice.npy'\\n    t_file = 't_slice.npy'\\n    beta_file = 'beta_slice.npy'\\n\\n    np.save(p_file,p_vals)\\n    np.save(t_file, t_vals)\\n    np.save(beta_file,beta_vals)\\n\\n    p_slice = abspath(p_file)\\n    t_slice = abspath(t_file)\\n    beta_slice = abspath(beta_file)\\n    return(p_slice,beta_slice,t_slice)\\n\"), ('model', <bound method Model.from_formula of <class 'statsmodels.regression.linear_model.OLS'>>), ('model_formula', 'Y ~ age'), ('n_terms', 1), ('needed_outputs', ['beta_slice', 'p_slice', 't_slice'])], 334cc232db405113e1b8eaf7b7b9ceb5, /Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/_0x334cc232db405113e1b8eaf7b7b9ceb5.json, ['/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/_0x1ce0025b0f267bbf0dc8c5d578771790.json']210701-16:07:23,47 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_run_models1\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models1\".\n",
      "\n",
      "210701-16:07:23,54 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_run_models0\".210701-16:07:23,56 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_run_models1\".\n",
      "\n",
      "210701-16:07:23,70 nipype.workflow DEBUG:\n",
      "\t [Node] Old/new hashes = 1ce0025b0f267bbf0dc8c5d578771790/334cc232db405113e1b8eaf7b7b9ceb5\n",
      "210701-16:07:23,113 nipype.utils DEBUG:\n",
      "\t Removing contents of /Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0210701-16:07:23,113 nipype.workflow INFO:\n",
      "\t [Node] Running \"_run_models1\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "\n",
      "210701-16:07:23,134 nipype.workflow DEBUG:\n",
      "\t Unable to write a particular type to the json file\n",
      "210701-16:07:23,148 nipype.workflow DEBUG:\n",
      "\t [Node] Writing pre-exec report to \"/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/_report/report.rst\"\n",
      "210701-16:07:23,161 nipype.workflow INFO:\n",
      "\t [Node] Running \"_run_models0\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "210701-16:07:24,970 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 2 tasks, and 2 jobs ready. Free memory (GB): 14.00/14.40, Free processors: 0/2.\n",
      "                     Currently running:\n",
      "                       * _run_models1\n",
      "                       * _run_models0\n",
      "210701-16:10:00,581 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_run_models1\".\n",
      "210701-16:10:00,861 nipype.workflow DEBUG:\n",
      "\t Needed files: /Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/beta_slice.npy;/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/p_slice.npy;/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/t_slice.npy;/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/_0x334cc232db405113e1b8eaf7b7b9ceb5_unfinished.json;/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/_inputs.pklz;/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/_node.pklz\n",
      "210701-16:10:00,868 nipype.workflow DEBUG:\n",
      "\t Needed dirs: /Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/_report\n",
      "210701-16:10:00,884 nipype.workflow DEBUG:\n",
      "\t Removing files: \n",
      "210701-16:10:00,893 nipype.workflow DEBUG:\n",
      "\t Saving results file: '/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/result__run_models0.pklz'\n",
      "210701-16:10:00,906 nipype.workflow DEBUG:\n",
      "\t [Node] Writing post-exec report to \"/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/_report/report.rst\"\n",
      "210701-16:10:00,925 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_run_models0\".\n",
      "210701-16:10:01,167 nipype.workflow INFO:\n",
      "\t [Job 10] Completed (_run_models0).\n",
      "210701-16:10:01,168 nipype.workflow INFO:\n",
      "\t [Job 11] Completed (_run_models1).\n",
      "210701-16:10:01,171 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 2 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "210701-16:10:01,226 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_run_models2\".\n",
      "210701-16:10:01,230 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_run_models2\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models2\".210701-16:10:01,232 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_run_models3\".\n",
      "\n",
      "210701-16:10:01,234 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_run_models2\".\n",
      "210701-16:10:01,237 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_run_models3\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3\".\n",
      "210701-16:10:01,243 nipype.workflow DEBUG:\n",
      "\t [Node] Hashes: [('covariates',      folder  age\n",
      "5  1196_PP1   68\n",
      "6  1196_PP2   76\n",
      "7  1196_PP3   96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  1196_PP4  106), ('data_stack', [('/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/1196_PP1.thickness.32k_fs_LR.dscalar.slice.npy', '0d0d3989b57747553aed75139a588801'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/1196_PP2.thickness.32k_fs_LR.dscalar.slice.npy', '1ccaeaa8164b518c66b60388a5d63f3b'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/1196_PP3.thickness.32k_fs_LR.dscalar.slice.npy', '3f285995d0b8c325b8719634b3aa3fa0'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/pull_data/mapflow/_pull_data3/1196_PP4.thickness.32k_fs_LR.dscalar.slice.npy', '7eb55f2f78a223497e2f6fba4e8fbadb')]), ('function_str', \"def run_long_models(model,model_formula,data_stack,covariates,n_terms):\\n    import numpy as np\\n    from os.path import basename,abspath\\n\\n    data_list = []\\n    for d in data_stack:\\n        t = np.load(d)\\n        t = np.expand_dims(t,axis=2)\\n        data_list.append(t)\\n\\n    sub_data = np.concatenate(data_list, axis=2)\\n\\n    m = sub_data.shape[0]\\n    n = sub_data.shape[1]\\n\\n    p_vals = np.zeros((m,n,n_terms+1))\\n    t_vals = np.zeros((m,n,n_terms+1))\\n    beta_vals = np.zeros((m,n,n_terms+1))\\n\\n    for a in range(0,m):\\n        for b in range(0,n):\\n            covariates['Y'] = sub_data[a,b,:]\\n            mdl = model(formula=model_formula, data=covariates).fit()\\n            beta_vals[a,b,:] = mdl.params\\n            p_vals[a,b,:] = mdl.pvalues\\n            t_vals[a,b,:] = mdl.tvalues\\n\\n    p_file = 'p_slice.npy'\\n    t_file = 't_slice.npy'\\n    beta_file = 'beta_slice.npy'\\n\\n    np.save(p_file,p_vals)\\n    np.save(t_file, t_vals)\\n    np.save(beta_file,beta_vals)\\n\\n    p_slice = abspath(p_file)\\n    t_slice = abspath(t_file)\\n    beta_slice = abspath(beta_file)\\n    return(p_slice,beta_slice,t_slice)\\n\"), ('model', <bound method Model.from_formula of <class 'statsmodels.regression.linear_model.OLS'>>), ('model_formula', 'Y ~ age'), ('n_terms', 1), ('needed_outputs', ['beta_slice', 'p_slice', 't_slice'])], 8ab42e7b093353c6dc68658a62a0cfe1, /Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/_0x8ab42e7b093353c6dc68658a62a0cfe1.json, ['/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/_0xdf994cefff71bb489eeee570fc956902.json']\n",
      "210701-16:10:01,250 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"_run_models3\".\n",
      "210701-16:10:01,255 nipype.workflow DEBUG:\n",
      "\t [Node] Old/new hashes = df994cefff71bb489eeee570fc956902/8ab42e7b093353c6dc68658a62a0cfe1\n",
      "210701-16:10:01,277 nipype.utils DEBUG:\n",
      "\t Removing contents of /Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3\n",
      "210701-16:10:01,295 nipype.workflow INFO:\n",
      "\t [Node] Running \"_run_models2\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "210701-16:10:01,317 nipype.workflow DEBUG:\n",
      "\t Unable to write a particular type to the json file\n",
      "210701-16:10:01,323 nipype.workflow DEBUG:\n",
      "\t [Node] Writing pre-exec report to \"/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/_report/report.rst\"\n",
      "210701-16:10:01,329 nipype.workflow INFO:\n",
      "\t [Node] Running \"_run_models3\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "210701-16:10:03,167 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 2 tasks, and 0 jobs ready. Free memory (GB): 14.00/14.40, Free processors: 0/2.\n",
      "                     Currently running:\n",
      "                       * _run_models3\n",
      "                       * _run_models2\n",
      "210701-16:12:37,589 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_run_models2\".\n",
      "210701-16:12:37,984 nipype.workflow DEBUG:\n",
      "\t Needed files: /Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/beta_slice.npy;/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/p_slice.npy;/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/t_slice.npy;/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/_0x8ab42e7b093353c6dc68658a62a0cfe1_unfinished.json;/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/_inputs.pklz;/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/_node.pklz\n",
      "210701-16:12:37,988 nipype.workflow DEBUG:\n",
      "\t Needed dirs: /Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/_report\n",
      "210701-16:12:37,992 nipype.workflow DEBUG:\n",
      "\t Removing files: \n",
      "210701-16:12:38,0 nipype.workflow DEBUG:\n",
      "\t Saving results file: '/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/result__run_models3.pklz'\n",
      "210701-16:12:38,11 nipype.workflow DEBUG:\n",
      "\t [Node] Writing post-exec report to \"/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/_report/report.rst\"\n",
      "210701-16:12:38,29 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_run_models3\".\n",
      "210701-16:12:39,370 nipype.workflow INFO:\n",
      "\t [Job 12] Completed (_run_models2).\n",
      "210701-16:12:39,371 nipype.workflow INFO:\n",
      "\t [Job 13] Completed (_run_models3).\n",
      "210701-16:12:39,374 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "210701-16:12:39,453 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"long_model.run_models\".\n",
      "210701-16:12:39,481 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"long_model.run_models\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models\".\n",
      "210701-16:12:39,486 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"long_model.run_models\".\n",
      "210701-16:12:39,503 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_run_models0\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0\".\n",
      "210701-16:12:39,517 nipype.workflow INFO:\n",
      "\t [Node] Cached \"_run_models0\" - collecting precomputed outputs\n",
      "210701-16:12:39,520 nipype.workflow INFO:\n",
      "\t [Node] \"_run_models0\" found cached.\n",
      "210701-16:12:39,525 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_run_models1\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models1\".\n",
      "210701-16:12:39,553 nipype.workflow INFO:\n",
      "\t [Node] Cached \"_run_models1\" - collecting precomputed outputs\n",
      "210701-16:12:39,556 nipype.workflow INFO:\n",
      "\t [Node] \"_run_models1\" found cached.\n",
      "210701-16:12:39,561 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_run_models2\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models2\".\n",
      "210701-16:12:39,626 nipype.workflow INFO:\n",
      "\t [Node] Cached \"_run_models2\" - collecting precomputed outputs\n",
      "210701-16:12:39,629 nipype.workflow INFO:\n",
      "\t [Node] \"_run_models2\" found cached.\n",
      "210701-16:12:39,635 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_run_models3\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3\".\n",
      "210701-16:12:39,705 nipype.workflow INFO:\n",
      "\t [Node] Cached \"_run_models3\" - collecting precomputed outputs\n",
      "210701-16:12:39,708 nipype.workflow INFO:\n",
      "\t [Node] \"_run_models3\" found cached.\n",
      "210701-16:12:39,720 nipype.workflow INFO:\n",
      "\t [Node] Finished \"long_model.run_models\".\n",
      "210701-16:12:41,372 nipype.workflow INFO:\n",
      "\t [Job 3] Completed (long_model.run_models).\n",
      "210701-16:12:41,374 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "210701-16:12:41,432 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"long_model.recombine_data\".\n",
      "210701-16:12:41,434 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"long_model.recombine_data\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data\".\n",
      "210701-16:12:41,439 nipype.workflow DEBUG:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [Node] Hashes: [('beta_list', [('/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/beta_slice.npy', 'bf4a27929aa6c34cf65c8431d9be8267'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models1/beta_slice.npy', 'b527e8e4f15a60b08eded4785d9a8ae2'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models2/beta_slice.npy', 'd1c2b06bfb0335f0d3a72b42f95c4281'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/beta_slice.npy', '6749eca3afabd1653a3eff0742715d33')]), ('file_list', [('/Users/SEAlab/Documents/PPM/Data/1196_PP1/MNINonLinear/fsaverage_LR32k/1196_PP1.thickness.32k_fs_LR.dscalar.nii', '5513fee4425ac7b6f188d858bae92f20'), ('/Users/SEAlab/Documents/PPM/Data/1196_PP2/MNINonLinear/fsaverage_LR32k/1196_PP2.thickness.32k_fs_LR.dscalar.nii', '5e2078d3ae95261f87ad219bee55a174'), ('/Users/SEAlab/Documents/PPM/Data/1196_PP3/MNINonLinear/fsaverage_LR32k/1196_PP3.thickness.32k_fs_LR.dscalar.nii', '54ce678d535576a68da3a11d2e769a6d'), ('/Users/SEAlab/Documents/PPM/Data/1196_PP4/MNINonLinear/fsaverage_LR32k/1196_PP4.thickness.32k_fs_LR.dscalar.nii', '780477b1c14c4ca08d06464af7ee2f0b')]), ('function_str', \"def combine_data(p_list,beta_list,t_list,index_list,n_terms,file_list):\\n    import nibabel as nib\\n    import numpy as np\\n    from os.path import abspath\\n\\n    img = nib.load(file_list[0])\\n    img_data = img.get_fdata()\\n\\n    p_data = np.empty((img_data.shape[0],img_data.shape[1],n_terms+1))\\n    t_data = np.empty((img_data.shape[0],img_data.shape[1],n_terms+1))\\n    beta_data = np.empty((img_data.shape[0],img_data.shape[1],n_terms+1))\\n\\n    print(index_list)\\n\\n    for x in range(0,len(index_list)):\\n        p_data[:,index_list[x],:] = np.load(p_list[x])\\n        t_data[:,index_list[x],:] = np.load(t_list[x])\\n        beta_data[:,index_list[x],:] = np.load(beta_list[x])\\n\\n    # get cifti header info from first file\\n    bm = img.header.get_axis(1)\\n    sc = img.header.get_axis(0)\\n\\n    pval_cifti = []\\n    tstat_cifti = []\\n    beta_cifti = []\\n\\n    for x in range(0,n_terms+1):\\n        # p-values\\n        temp_p = p_data[:,:,x]\\n        temp_p[temp_p>.05] = 1\\n        sc.name = ['pvalues']\\n        p_img = nib.cifti2.cifti2.Cifti2Image(temp_p,(sc,bm))\\n        nib.save(p_img,'model_pvalues_term{0}.dscalar.nii'.format(x))\\n        pval_cifti.append(abspath('model_pvalues_term{0}.dscalar.nii'.format(x)))\\n        # t-values\\n        temp_t = t_data[:,:,x]\\n        temp_t[temp_p>.05] = 0\\n        sc.name = ['tvalues']\\n        t_img = nib.cifti2.cifti2.Cifti2Image(temp_t,(sc,bm))\\n        nib.save(t_img,'model_tvalues_term{0}.dscalar.nii'.format(x))\\n        tstat_cifti.append(abspath('model_tvalues_term{0}.dscalar.nii'.format(x)))\\n        #beta values\\n        temp_b = beta_data[:,:,x]\\n        temp_b[temp_p>.05] = 0\\n        sc.name = ['beta']\\n        b_img = nib.cifti2.cifti2.Cifti2Image(temp_b,(sc,bm))\\n        nib.save(b_img,'model_beta_term{0}.dscalar.nii'.format(x))\\n        beta_cifti.append(abspath('model_beta_term{0}.dscalar.nii'.format(x)))\\n\\n    return(pval_cifti,beta_cifti,tstat_cifti)\\n\"), ('index_list', [slice(0, 14853, None), slice(14853, 29706, None), slice(29706, 44559, None), slice(44559, 59412, None)]), ('n_terms', 1), ('p_list', [('/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/p_slice.npy', '0f295a3e43b2147694eef2e7a0f2a1b7'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models1/p_slice.npy', 'c69827dcd6f18866b8eea82bef057214'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models2/p_slice.npy', '3125ecfc359a6f06dd25fa9a647ffd4b'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/p_slice.npy', '888069c4b5360e9089fa51e5c3fe0b8b')]), ('t_list', [('/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models0/t_slice.npy', '780823f9f1acfc638993518edcaa55fa'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models1/t_slice.npy', 'e5cc157a1b3f5f88b36a0a793faffe53'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models2/t_slice.npy', '74747f316d7706cb8c4b0657bee1c8d0'), ('/Users/SEAlab/Documents/PPM/Workflows/long_model/run_models/mapflow/_run_models3/t_slice.npy', 'e2159f1f3516ed4a23e1433b7c896617')]), ('needed_outputs', ['beta_cifti', 'pval_cifti', 'tstat_cifti'])], d33435e65a49906e7ccf21358ac2675a, /Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/_0xd33435e65a49906e7ccf21358ac2675a.json, ['/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/_0xa59e30ae70ea1ce50a3f8de1c29ea236.json']\n",
      "210701-16:12:41,444 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"long_model.recombine_data\".\n",
      "210701-16:12:41,448 nipype.workflow DEBUG:\n",
      "\t [Node] Old/new hashes = a59e30ae70ea1ce50a3f8de1c29ea236/d33435e65a49906e7ccf21358ac2675a\n",
      "210701-16:12:41,471 nipype.utils DEBUG:\n",
      "\t Removing contents of /Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data\n",
      "210701-16:12:41,501 nipype.workflow DEBUG:\n",
      "\t Unable to write a particular type to the json file\n",
      "210701-16:12:41,506 nipype.workflow DEBUG:\n",
      "\t [Node] Writing pre-exec report to \"/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/_report/report.rst\"\n",
      "210701-16:12:41,514 nipype.workflow INFO:\n",
      "\t [Node] Running \"recombine_data\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "[slice(0, 14853, None), slice(14853, 29706, None), slice(29706, 44559, None), slice(44559, 59412, None)]\n",
      "210701-16:12:43,376 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 0 jobs ready. Free memory (GB): 14.20/14.40, Free processors: 1/2.\n",
      "                     Currently running:\n",
      "                       * long_model.recombine_data\n",
      "210701-16:12:45,347 nipype.workflow DEBUG:\n",
      "\t Needed files: /Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/model_beta_term0.dscalar.nii;/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/model_beta_term0.dscalar.mat;/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/model_beta_term1.dscalar.nii;/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/model_beta_term1.dscalar.mat;/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/model_pvalues_term0.dscalar.nii;/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/model_pvalues_term0.dscalar.mat;/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/model_pvalues_term1.dscalar.nii;/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/model_pvalues_term1.dscalar.mat;/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/model_tvalues_term0.dscalar.nii;/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/model_tvalues_term0.dscalar.mat;/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/model_tvalues_term1.dscalar.nii;/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/model_tvalues_term1.dscalar.mat;/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/_0xd33435e65a49906e7ccf21358ac2675a_unfinished.json;/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/_inputs.pklz;/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/_node.pklz\n",
      "210701-16:12:45,352 nipype.workflow DEBUG:\n",
      "\t Needed dirs: /Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/_report\n",
      "210701-16:12:45,363 nipype.workflow DEBUG:\n",
      "\t Removing files: \n",
      "210701-16:12:45,366 nipype.workflow DEBUG:\n",
      "\t Saving results file: '/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/result_recombine_data.pklz'\n",
      "210701-16:12:45,373 nipype.workflow DEBUG:\n",
      "\t [Node] Writing post-exec report to \"/Users/SEAlab/Documents/PPM/Workflows/long_model/recombine_data/_report/report.rst\"\n",
      "210701-16:12:45,396 nipype.workflow INFO:\n",
      "\t [Node] Finished \"long_model.recombine_data\".\n",
      "210701-16:12:47,383 nipype.workflow INFO:\n",
      "\t [Job 4] Completed (long_model.recombine_data).\n",
      "210701-16:12:47,386 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n",
      "210701-16:12:47,444 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"long_model.datasink\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210701-16:12:47,448 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"long_model.datasink\" in \"/Users/SEAlab/Documents/PPM/Workflows/long_model/datasink\".\n",
      "210701-16:12:47,455 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"long_model.datasink\".\n",
      "210701-16:12:47,477 nipype.workflow INFO:\n",
      "\t [Node] Running \"datasink\" (\"nipype.interfaces.io.DataSink\")\n",
      "210701-16:12:47,502 nipype.workflow INFO:\n",
      "\t [Node] Finished \"long_model.datasink\".\n",
      "210701-16:12:49,387 nipype.workflow INFO:\n",
      "\t [Job 5] Completed (long_model.datasink).\n",
      "210701-16:12:49,390 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 0 jobs ready. Free memory (GB): 14.40/14.40, Free processors: 2/2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7fbe574eafd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_model = Workflow(name='long_model', base_dir=workflow_dir)\n",
    "long_model.connect([(selectfiles,make_indexes,[('file_list','file_list')]),\n",
    "                    (selectfiles,pull_data,[('file_list','file_list')]),\n",
    "                    (selectfiles,recombine_data,[('file_list','file_list')]),\n",
    "                    (make_indexes, pull_data, [('indexes_list','index')]),\n",
    "                    (pull_data, run_models, [('data_stack','data_stack')]),\n",
    "                    (make_indexes, recombine_data, [('indexes_list','index_list')]),\n",
    "                    (run_models, recombine_data, [('p_slice','p_list'),\n",
    "                                                  ('beta_slice','beta_list'),\n",
    "                                                  ('t_slice','t_list')]),\n",
    "                    (recombine_data, datasink, [('pval_cifti','pvalues'),\n",
    "                                                ('beta_cifti','betas'),\n",
    "                                                ('tstat_cifti','tstats')])\n",
    "                   ])\n",
    "long_model.run('MultiProc', plugin_args={'n_procs':proc_cores})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull Parcel-Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set study variables\n",
    "study_home = '/Users/SEAlab/Documents/PPM'\n",
    "hcpproc_dir = study_home + '/Data'\n",
    "output_dir = study_home + '/fMRIproc/longitudinal/struct_data'\n",
    "cov_file = study_home + '/Misc/covariates.csv'\n",
    "cov_dataframe = pd.read_csv(cov_file,index_col=None)\n",
    "cov_dataframe = cov_dataframe.sort_values(by='folder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_freesurfer_data(subject_list,data_filepath,outfile_name):\n",
    "    import pandas as pd\n",
    "    \n",
    "    \n",
    "    sub_dfs = []\n",
    "\n",
    "    if 'aseg.stats' in data_filepath:\n",
    "        columns = ['Index','SegId','NVoxels','Volume_mm3','StructName','normMean','normStdDev','normMin','normMax','normRange']\n",
    "        for sub in subject_list:\n",
    "            file = data_filepath.format(sub)\n",
    "            df = pd.read_csv(file,index_col='StructName',comment='#',sep='\\s+',header=None, names=columns)\n",
    "            df = df[['Volume_mm3']].transpose()\n",
    "            df.index=[sub]\n",
    "            sub_dfs.append(df)\n",
    "\n",
    "    elif 'aparc' in data_filepath:\n",
    "        columns = ['StructName','NumVert','SurfArea','GrayVol','ThickAvg','ThickStd','MeanCurv','GausCurv','FoldInd','CurvInd']\n",
    "        for sub in subject_list:\n",
    "            file = data_filepath.format(sub)\n",
    "            df = pd.read_csv(file,index_col='StructName',comment='#',sep='\\s+',header=None, names=columns)\n",
    "            df = df[['SurfArea','GrayVol','ThickAvg']].transpose()\n",
    "            df['measure'] = df.index\n",
    "            df.index=[sub,sub,sub]\n",
    "            sub_dfs.append(df)\n",
    "\n",
    "    if 'brainvol' in data_filepath:\n",
    "        columns = ['StructName','Description','Volume_mm3','metric']\n",
    "        for sub in subject_list:\n",
    "            file = data_filepath.format(sub)\n",
    "            df = pd.read_csv(file,index_col=None,header=None, names=columns)\n",
    "            df.index = df['StructName']\n",
    "            df = df[['Volume_mm3']].transpose()\n",
    "            df.index=[sub]\n",
    "            sub_dfs.append(df)\n",
    "\n",
    "    full_data = pd.concat(sub_dfs)\n",
    "    full_data.to_csv('{0}.csv'.format(outfile_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = cov_dataframe['folder']\n",
    "stat_list = [hcpproc_dir+'/{0}/T1w/{0}/stats/brainvol.stats',\n",
    "             hcpproc_dir+'/{0}/T1w/{0}/stats/aseg.stats',\n",
    "             hcpproc_dir+'/{0}/T1w/{0}/stats/lh.aparc.DKTatlas.stats',\n",
    "             hcpproc_dir+'/{0}/T1w/{0}/stats/rh.aparc.DKTatlas.stats',]\n",
    "outnames = [output_dir+'/brain_volumes',\n",
    "            output_dir+'/segmentation',\n",
    "            output_dir+'/left_DKTparc',\n",
    "            output_dir+'/right_DKTparc']\n",
    "\n",
    "for i, stat in enumerate(stat_list):\n",
    "    combine_freesurfer_data(subject_list,stat,outnames[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
